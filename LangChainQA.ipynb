{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "openai.api_key = \"<api_key>\"\n",
    "\n",
    "\n",
    "\n",
    "llm_model = \"gpt-3.5-turbo\"\n",
    "\n",
    "\n",
    "prompt = \"Convert this text into polite american english 'Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse, \\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!'\"\n",
    "\n",
    "\n",
    "message = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "response = openai.chat.completions.create(model=llm_model, messages=message, temperature=0.0)\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.00, model = \"gpt-3.5-turbo\", api_key=\"<API_KEY>\")\n",
    "chat\n",
    "template_string = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \\\n",
    "into a style that is {style}. \\\n",
    "text: ```{text}```\n",
    "\"\"\"\n",
    "my_prompt = ChatPromptTemplate.from_template(template_string)\n",
    "my_prompt.input_variables\n",
    "\n",
    "customer_style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\"\n",
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse, \\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\"\n",
    "\n",
    "cust_messages = my_prompt.format_messages(style = customer_style, text = customer_email)\n",
    "\n",
    "cust_messages\n",
    "\n",
    "chat(cust_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "my_llm = ChatOpenAI(temperature=0.0, model = \"gpt-3.5-turbo\", api_key=\"<API_Key>\")\n",
    "\n",
    "my_conversation = ConversationChain(llm=my_llm, memory=ConversationBufferMemory(), verbose=False)\n",
    "\n",
    "print(my_conversation.predict(input=\"My name is Koushik and I live in India.\"))\n",
    "print(my_conversation.predict(input=\"What is 1+1?\"))\n",
    "print(my_conversation.predict(input=\"What is my name?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "my_llm = ChatOpenAI(temperature=0.0, api_key=\"<API_KET>\")\n",
    "\n",
    "my_memory=ConversationBufferMemory()\n",
    "\n",
    "my_memory.save_context({\"input\": \"Hi\"}, {\"output\": \"Hello! Whats up?\"})\n",
    "my_memory.save_context({\"input\": \"All good.\"}, {\"output\": \"Cool. Tell me what I can do with you?\"})\n",
    "my_conversation = ConversationChain(llm=my_llm, memory=my_memory, verbose=False)\n",
    "\n",
    "\n",
    "\n",
    "#print(my_conversation.predict(input=\"My name is Koushik and I live in India.\"))\n",
    "#print(my_conversation.predict(input=\"What is 1+1?\"))\n",
    "#print(my_conversation.predict(input=\"What is my name?\"))\n",
    "#my_conversation.predict(input=\"All good.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools, initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "my_llm = ChatOpenAI(temperature=0.0, model = \"gpt-3.5-turbo\", api_key=\"<API_KEY\")\n",
    "\n",
    "my_tool = load_tools([\"llm-math\",\"wikipedia\"], llm=my_llm)\n",
    "\n",
    "my_agent = initialize_agent(my_tool, my_llm, agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION, handle_parsing_errors=True, verbose = False)\n",
    "\n",
    "#my_agent(\"What is the 25% of 300?\")\n",
    "\n",
    "my_agent(\"When was french revolution happened?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
